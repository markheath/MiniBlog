<post>
  <title>Handling multi-channel audio in NAudio</title>
  <slug>handling-multi-channel-audio-in-naudio</slug>
  <author>Mark Heath</author>
  <pubDate>2012-01-27 18:54:00</pubDate>
  <lastModified>2012-01-27 18:54:00</lastModified>
  <content>&lt;p&gt;One of the recurring questions on the &lt;a href="http://naudio.codeplex.com"&gt;NAudio&lt;/a&gt; support forums is to do with how you can route different sounds to different outputs in a multi-channel soundcard setup. For example, can you play one MP3 file out of one speaker and a different one out of the other? If you have four outputs, can you route a different signal to each one?&lt;/p&gt; &lt;p&gt;The first issue to deal with is that just because your soundcard has multiple outputs, doesn’t mean you can necessarily open WaveOut with multiple outs. That depends on how the writers of the device driver have chosen to present the card’s capabilities to Windows. For example a four output card may appear as though it were two separate stereo soundcards. The good news is that if you have an ASIO driver, you ought to be able to open it and address all the outputs.&lt;/p&gt; &lt;p&gt;Having got that out of the way, in NAudio it is possible for audio streams to have any number of channels. The WaveFormat class has a channel count, and though this is normally set at 1 or 2, there is no reason why you can’t set it to 8.&lt;/p&gt; &lt;p&gt;What would be useful is an implementation of IWaveProvider that allows us to connect different inputs to particular outputs, kind of like a virtual patch bay. For example, if you had two Mp3FileReaders, and wanted to connect the left channel of the first to output 1 and the left channel of the second to output 2, this class would let you do that.&lt;/p&gt; &lt;p&gt;So I’ve created something I’ve called the &lt;strong&gt;MultiplexingWaveProvider&lt;/strong&gt; (if you can think of a better name, let me know in the comments). In the constructor, you simply provide all the inputs you wish to use, and specify the number of output channels you would like. By default the inputs will be mapped directly onto the outputs (and wrap round if there are less outputs than inputs – so a single mono input would be automatically copied to every output), but these can be changed.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Creating and Configuring MultiplexingWaveProvider&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In the following example, we create a new four-channel WaveProvider, so the first two outputs will play left and right channel from &lt;strong&gt;input1&lt;/strong&gt; and the second two outputs will have the left and right channels from &lt;strong&gt;input2&lt;/strong&gt;.&lt;strong&gt; &lt;/strong&gt;Note that input1 and input2 must be at the same sample rate and bit depth.&lt;/p&gt;&lt;pre class="brush: csharp;"&gt;var input1 = new Mp3FileReader("test1.mp3");
var input2 = new Mp3FileReader("test2.mp3");
var waveProvider = new MultiplexingWaveProvider(new IWaveProvider[] { input1, input2 }, 4));
&lt;/pre&gt;
&lt;p&gt;Then you can configure the outputs, which is done using &lt;strong&gt;ConnectInputToOutput&lt;/strong&gt;:&lt;/p&gt;&lt;pre class="brush: csharp;"&gt;waveProvider.ConnectInputToOutput(2,0);
waveProvider.ConnectInputToOutput(3,1);
waveProvider.ConnectInputToOutput(1,2);
waveProvider.ConnectInputToOutput(1,3);
&lt;/pre&gt;
&lt;p&gt;The numbers used are zero-based, so connecting inputs 2 and 3 to outputs 0 and 1 means that test2.mp3 will now play out of the first two outputs instead of the second two. In this example I have connected input 1 (i.e. the right channel of test1.mp3) to both outputs 2 and 3. So you can copy the same input to multiple output channels, and not all input channels need a mapping.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Implementation of MultiplexingWaveProvider&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The bulk of the work to achieve this is performed in the Read method of MultiplexingWaveProvider. The first task is to work out how many “sample frames” are required. A sample frame is a single sample in a mono signal, a left and right pair in a stereo signal, and so on. Once we have worked out how many sample frames we need, we then attempt to read that many sample frames from every one of the input WaveProviders (irrespective of whether they are connected to an output – we want to keep them in sync). Then, using our mappings dictionary, work out if any of the channels from this input WaveProvider are needed in the output. Since samples are interleaved in both input and output waveproviders, we can’t do just one Array.Copy – we must copy each sample across individually and put it into the right place.&lt;/p&gt;
&lt;p&gt;A well behaved Read method will always return count unless it has reached the end of its available data (and then it should always return 0 in every subsequent call). The way we do this is work out the maximum number of sample frames read out of any of the inputs, and use that to report back the count that is read. This means that we will keep going until we have reached the end of all of our inputs. Because buffers might be reused, it is important that we zero out the output buffer if there was no available input data. &lt;/p&gt;
&lt;p&gt;Here’s the implementation as it currently stands:&lt;/p&gt;&lt;pre class="brush: csharp;"&gt;public int Read(byte[] buffer, int offset, int count)
{
    int sampleFramesRequested = count / (bytesPerSample * outputChannelCount);
    int inputOffset = 0;
    int sampleFramesRead = 0;
    // now we must read from all inputs, even if we don't need their data, so they stay in sync
    foreach (var input in inputs)
    {
        int bytesRequired = sampleFramesRequested * bytesPerSample * input.WaveFormat.Channels;
        byte[] inputBuffer = new byte[bytesRequired];
        int bytesRead = input.Read(inputBuffer, 0, bytesRequired);
        sampleFramesRead = Math.Max(sampleFramesRead, bytesRead / (bytesPerSample * input.WaveFormat.Channels));

        for (int n = 0; n &amp;lt; input.WaveFormat.Channels; n++)
        {
            int inputIndex = inputOffset + n;
            for (int outputIndex = 0; outputIndex &amp;lt; outputChannelCount; outputIndex++)
            {
                if (mappings[outputIndex] == inputIndex)
                {
                    int inputBufferOffset = n * bytesPerSample;
                    int outputBufferOffset = offset + outputIndex * bytesPerSample;
                    int sample = 0;
                    while (sample &amp;lt; sampleFramesRequested &amp;amp;&amp;amp; inputBufferOffset &amp;lt; bytesRead)
                    {
                        Array.Copy(inputBuffer, inputBufferOffset, buffer, outputBufferOffset, bytesPerSample);
                        outputBufferOffset += bytesPerSample * outputChannelCount;
                        inputBufferOffset += bytesPerSample * input.WaveFormat.Channels;
                        sample++;
                    }
                    // clear the end
                    while (sample &amp;lt; sampleFramesRequested)
                    {
                        Array.Clear(buffer, outputBufferOffset, bytesPerSample);
                        outputBufferOffset += bytesPerSample * outputChannelCount;
                        sample++;
                    }
                }
            }
        }
        inputOffset += input.WaveFormat.Channels;
    }

    return sampleFramesRead * bytesPerSample * outputChannelCount;
}
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Looking at the code above, you will probably notice that this could be made more efficient if we knew in advance whether we were dealing with 16, 24 or 32 bit input audio (it currently has lots of calls to Array.Copy to copy just 2, 3 or 4 bytes). And I might make three versions of this class at some point, to ensure that this performs a bit better. Another weakness in the current design is the creation of buffers every call to Read, which is something that I generally avoid since it gives work to the garbage collector (&lt;em&gt;update – this is fixed in the latest code&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;I have written a full suite of unit tests for this class, so if it does need some performance tuning, there is a safety net to ensure nothing gets broken along the way.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MultiplexingSampleProvider&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NAudio 1.5 also has a ISampleProvider interface, which is a much more programmer friendly way of dealing with 32 bit floating point audio. I have also made &lt;strong&gt;MultiplexingSampleProvider &lt;/strong&gt;for the next version of NAudio. One interesting possibility would be then to build on that to create a kind of bus matrix, where every input can be mixed by different amounts into each of the output channels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Uses&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This class actually has uses beyond supporting soundcards with more than 2 outputs. You could use it to swap left and right channels in a stereo signal, or provide a simple switch that selects between several mono inputs.&lt;/p&gt;
&lt;p&gt;You also don’t need to output to the soundcard. The WaveFileReader will happily write multi-channel WAV files. However, there are no guarantees about how other programs will deal with WAVs that have more than two channels in them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ve already checked in the initial version to the latest codebase, so expect this to be part of NAudio 1.6. The only caution is that I might change the class name if I come up with a better idea. &lt;/p&gt;  </content>
  <ispublished>true</ispublished>
  <categories>
    <category>NAudio</category>
  </categories>
  <comments>
    <comment isAdmin="false" isApproved="true" id="68039453-5c61-4faf-96d6-0bdf043ae3d1">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-04-05 11:32:44</date>
      <content>I&amp;#39;m very new to audio programming and I have been trying demos to setup a framework for realtime multichannel playback from a continous stream of multi channel float data at 20 kHz but I don&amp;#39;t know where to start best:&lt;br /&gt;&lt;br /&gt;At a speed of 20 kHz a callback is made to an event handler to provide an array of 32 float values. I want to mix the float values realtime and pass them through an effects library prior to playback.&lt;br /&gt;Please help me out here</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="d5f8cc75-ae2c-4693-9b3c-aa88fb13a98c">
      <author>bull</author>
      <email>noreply@blogger.com</email>
      <website>http://www.ellismis.com</website>
      <ip />
      <userAgent />
      <date>2012-04-10 16:06:00</date>
      <content>Hey Mark,&lt;br /&gt;&lt;br /&gt;Great article!&lt;br /&gt;&lt;br /&gt;Could one use this code or nAudio to do per channel mute gain on playback of a multi channel ogg vorbis file?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a5457d34-7cf7-4e28-a9ae-ab000aa231f3">
      <author>mike</author>
      <email>noreply@blogger.com</email>
      <website>http://www.ellismis.com</website>
      <ip />
      <userAgent />
      <date>2012-04-10 16:06:22</date>
      <content>Hey Mark,&lt;br /&gt;&lt;br /&gt;Great article!&lt;br /&gt;&lt;br /&gt;Could one use this code or nAudio to do per channel mute gain on playback of a multi channel file</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="679ebb69-9aa7-45de-b6be-23e8d7502b0f">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-04-16 08:40:09</date>
      <content>yes, you could extend this class fairly easily to support muting and adjusting the gain of channels (especially in the ISampleProvider version)</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="8fad612f-d616-4767-a076-f1bbb2e54184">
      <author>Anders</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-05-11 13:36:01</date>
      <content>Hi Mark&lt;br /&gt;&lt;br /&gt;Hi i have problems with the MultiplexingWaveProvider. &lt;br /&gt;I want to play a sound out of the right channel i can get it to play out of the left channel if i create a MultiplexingWaveProvider with one output, but when i create it with 2 outputs it plays in both channels no matter how i connect the inputs to outputs.&lt;br /&gt;&lt;br /&gt;Here is my code.&lt;br /&gt;  var waveProvider = new MultiplexingWaveProvider(new IWaveProvider[] { mainOutputStream }, 2 );&lt;br /&gt;&lt;br /&gt;            waveProvider.ConnectInputToOutput(0, 1);&lt;br /&gt;            waveProvider.ConnectInputToOutput(1, 1);&lt;br /&gt;            &lt;br /&gt;            AsioOut dfd = new AsioOut();&lt;br /&gt;            string ffd = dfd.DriverName;&lt;br /&gt;            dfd.Init(waveProvider);&lt;br /&gt;            dfd.Play();&lt;br /&gt;&lt;br /&gt;Thanks&lt;br /&gt;Anders</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="68cfcc96-0aa5-4bf3-bd91-dff703bffdbe">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-05-14 11:51:32</date>
      <content>you can&amp;#39;t route two inputs to one output. Also, there is no way to disconnect an output at the moment (something I plan to add later). For now you could make a silence producing WaveProvider (very easy to implement) and route that to the output you want silent.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="dccedd99-44f1-4b83-95e8-91af57b30f7c">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-19 08:37:14</date>
      <content>Hi Mark!&lt;br /&gt;&lt;br /&gt;Can you give any hints how to implement the silence producing wave provider? I&amp;#39;m quite new to sound programming...&lt;br /&gt;&lt;br /&gt;Best regards</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="35b137fc-d082-4abe-8449-50408cd5dabe">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-19 08:37:29</date>
      <content>Hi Mark!&lt;br /&gt;&lt;br /&gt;Can you give any hints how to implement the silence producing wave provider? I&amp;#39;m quite new to sound programming...&lt;br /&gt;&lt;br /&gt;Best regards</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a3ccf697-9a56-42c7-ad6b-001da456b9e0">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-06-19 09:27:31</date>
      <content>int Read(byte[] buffer, int offset, int count)&lt;br /&gt;{&lt;br /&gt;   for(int n = 0; n &amp;lt; count; n++)&lt;br /&gt;   {&lt;br /&gt;       buffer[n + offset] = 0;&lt;br /&gt;   }&lt;br /&gt;   return count;&lt;br /&gt;}</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="8d6e8f52-f838-4a10-8bd2-8dd6c7c614f2">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-19 12:04:10</date>
      <content>Thank you, it worked just fine!</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="f51ff8ba-24f1-494d-aa6b-18c87a1560f0">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-20 14:37:06</date>
      <content>Hi Mark,&lt;br /&gt;&lt;br /&gt;Excellent work on NAudio.&lt;br /&gt;&lt;br /&gt;I&amp;#39;m trying to perform something similar to the poster above; I&amp;#39;m trying to play a stereo source out of just one channel.&lt;br /&gt;&lt;br /&gt;This would mean converting it to Mono first (is this possible?) and then in theory playing silence over the other channel(s).&lt;br /&gt;&lt;br /&gt;In line with the above request, how would I route silence to, say channel 1 but still have an MP3 playing on channel 0 in mono?&lt;br /&gt;&lt;br /&gt;Many thanks in advance.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="fd0954a3-4ae7-4100-8e4b-f03aa4574cc1">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-06-21 09:43:57</date>
      <content>You won&amp;#39;t need to convert to mono first, just route the first channel. You would also make a silencewaveprovder using the code above, adding that as an input and then routing that to the channels you want silent.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="1765cf17-0d6b-471d-926f-75d622ee86a7">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-25 09:58:37</date>
      <content>Mark,&lt;br /&gt;&lt;br /&gt;Thanks for the advice.  I&amp;#39;ve spent some time over the weekend looking into things further and I feel I have a much better understanding of what&amp;#39;s going on.&lt;br /&gt;&lt;br /&gt;I&amp;#39;ve created a silenceproducingwaveprovider (spwp) and I&amp;#39;m playing an mp3, both channels of the mp3 routed to output channel 0 (left) and the spwp is routed to 1 (right).  This works perfectly and gives me a combined mono output in the left speaker and silence in the right as seen in the code below.&lt;br /&gt;&lt;br /&gt;However, when I try to create the MultiplexingWaveProvider with 6 output channels for a 5.1 setup (or any number other than 2), I receive the following exception: &amp;quot;InvalidParameter calling waveOutOpen&amp;quot;.  This happens when calling &amp;quot;Dim PlaybackDevice As New WaveOut&amp;quot;.  Am I missing something?  I have tried this one two different machines, both with 6 output channels available.&lt;br /&gt;&lt;br /&gt;Many thanks in advance... again.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;        Dim Mp3FileReader As New Mp3FileReader(&amp;quot;some path to mp3&amp;quot;)&lt;br /&gt;        &lt;br /&gt;        Dim SilenceProducingWaveProvider As New SilenceProducingWaveProvider&lt;br /&gt;&lt;br /&gt;        Dim MultiplexingWaveProvider As New MultiplexingWaveProvider(New IWaveProvider() {Mp3FileReader, SilenceProducingWaveProvider}, 2)&lt;br /&gt;&lt;br /&gt;        With MultiplexingWaveProvider&lt;br /&gt;            .ConnectInputToOutput(0, 0)&lt;br /&gt;            .ConnectInputToOutput(1, 0)&lt;br /&gt;            .ConnectInputToOutput(2, 1)&lt;br /&gt;            .ConnectInputToOutput(3, 1)&lt;br /&gt;        End With&lt;br /&gt;&lt;br /&gt;        Dim PlaybackDevice As New WaveOut&lt;br /&gt;&lt;br /&gt;        PlaybackDevice.Init(MultiplexingWaveProvider)&lt;br /&gt;        PlaybackDevice.Play()</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="aeb127fa-928b-4ca5-8d05-0c45d8c65047">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-06-26 10:41:27</date>
      <content>It may well be a limitation of the drivers for your WaveOut device. Just because your soundcard has 6 outputs, doesn&amp;#39;t mean it is presented to Windows as a 6 output card. It might be 3 stereo outs. Have you tried using WasapiOut instead, or DirectSoundOut?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="cf17cac3-4171-436e-87a8-fe6c826fd15d">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-26 12:22:59</date>
      <content>Thanks for the reply.  Since posting above I&amp;#39;ve tried the other providers and they&amp;#39;re all returning two channels so it looks like a driver issue.&lt;br /&gt;&lt;br /&gt;I&amp;#39;m able to use BASS.Net&amp;#39;s mixer to do what I&amp;#39;m trying above and it works except the two rear channel streams bleed into one another.  I was hoping that NAudio would not present this problem.&lt;br /&gt;&lt;br /&gt;Is there any way with NAudio, as there is with BASS to tell it to ignore what the driver reports and force the use of the Windows Control Panel driver count?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="dc83a04e-9e96-44bf-87a2-cd1c7cabac74">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-06-28 07:36:35</date>
      <content>Is it possible to change the channel volumes using this provider?&lt;br /&gt;&lt;br /&gt;I&amp;#39;ve had a try of multiplying various volumes by an integer in an effort to reduce the volume, but I&amp;#39;m not having any luck.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="1a841d08-18ef-4cc6-92de-00c159dc33ce">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-06-29 16:35:07</date>
      <content>I&amp;#39;m afraid I don&amp;#39;t know what BASS .NET does and how it lets you open with multi channels. NAudio just wraps the Windows APIs.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="f63a7062-16d4-4ef3-9145-3b74a62104ae">
      <author>Zxeltor</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-07-03 21:20:08</date>
      <content>Mark.  Thanks for posting this.  This post has been very helpful.&lt;br /&gt;&lt;br /&gt;I’m currently using this class to playback audio files on different channels (Left and Right).  Sometimes simultaneously.&lt;br /&gt;&lt;br /&gt;I’m curious.  The directsound device I’m using occasionally craps out and I have to kill my app.  I noticed when you init the default constructor for the directsound device, a guid is assigned.  Is it a bad idea to have more then one instance of this output device initialized and performing playback at the same time?&lt;br /&gt;&lt;br /&gt;Also … the example given above concerning the silence wave provider.  If count never returns zero the playback complete event will never get triggered when using the silence provider with another audio source.  I ended up keeping track of my silence streams position under the hood so my read method would eventually return zero.  Hopefully this will help any other code monkeys that stumble along.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="f0c7be4f-cfd7-409d-bfe2-949a067f0aca">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2012-08-31 08:56:56</date>
      <content>Hi Mark.&lt;br /&gt;Is there anyway to change speed of playing?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="96ba1c6a-c2df-4de2-bcba-6ac01be6bf71">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2012-09-05 17:24:50</date>
      <content>@Anonymous, not easily. You would need to make your own WaveProvider to provide the audio at a faster rate (e.g. skip every other sample for a very rudimentary approach)</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="775f2a7c-a841-487d-9d98-5c20380d1c9b">
      <author>m.bagattini</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/10120067328232989475</website>
      <ip />
      <userAgent />
      <date>2013-03-19 15:49:23</date>
      <content>Thanks for the article Mark! I&amp;#39;d like to use this method to play the same track on left/right channel, with one channel delayed; I&amp;#39;d like to try this since I noticed on some daleyed tracks that spoken words are more easily understandable. It&amp;#39;s just a theory but I&amp;#39;d like to give it a shot.&lt;br /&gt;&lt;br /&gt;So I have my mp3 playing on both earplugs now, do you have any suggestion about how to delay a single channel?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="56e546b2-7ae1-47e8-8c5b-e8e578cf3f94">
      <author>m.bagattini</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/10120067328232989475</website>
      <ip />
      <userAgent />
      <date>2013-03-19 15:49:53</date>
      <content>Thanks for the article Mark! I&amp;#39;d like to use this method to play the same track on left/right channel, with one channel delayed; I&amp;#39;d like to try this since I noticed on some daleyed tracks that spoken words are more easily understandable. It&amp;#39;s just a theory but I&amp;#39;d like to give it a shot.&lt;br /&gt;&lt;br /&gt;So I have my mp3 playing on both earplugs now, do you have any suggestion about how to delay a single channel?</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a707924e-50ba-495b-a5cf-ed86c840d679">
      <author>Peter v E</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/07132348897522279594</website>
      <ip />
      <userAgent />
      <date>2013-04-22 16:18:05</date>
      <content>Hi Mark,&lt;br /&gt;&lt;br /&gt;Frist of all: Great work on the whole project! It&amp;#39;s fun to work with and has all the functions one could ask for :)&lt;br /&gt;&lt;br /&gt;I do have a question about the MultiplexingWaveProvider. I&amp;#39;m using it to send a WaveChannel32 which contains a stream from the MP3FileReader to one channel of my sound card. The other channel gets a silent stream (a stream of zeros). This works and all. But how can i determine if the stream from the mp3FileReader is finished? The PlaybackStopped event isn&amp;#39;t raised because the silence stream keeps giving zeros.&lt;br /&gt;&lt;br /&gt;Is there a way to detect if the mp3FileReader stream is finished?&lt;br /&gt;&lt;br /&gt;This is the code i&amp;#39;m using:&lt;br /&gt;&lt;br /&gt;Try&lt;br /&gt;   outputStream = CreateInputStream(localFilePath)&lt;br /&gt;   Dim silenceStream As New SilenceWaveProvider&lt;br /&gt;   outDevice = New WasapiOut(device, AudioClientShareMode.Shared, True, 0)&lt;br /&gt;   Try&lt;br /&gt;      Dim multiplex As New MultiplexingWaveProvider(New IWaveProvider() {outputStream, silenceStream}, 2)&lt;br /&gt;      Select Case _channel&lt;br /&gt;          Case 0&lt;br /&gt;             multiplex.ConnectInputToOutput(0, 0)&lt;br /&gt;             multiplex.ConnectInputToOutput(1, 0)&lt;br /&gt;             multiplex.ConnectInputToOutput(2, 1)&lt;br /&gt;          Case 1&lt;br /&gt;             multiplex.ConnectInputToOutput(0, 1)&lt;br /&gt;             multiplex.ConnectInputToOutput(1, 0)&lt;br /&gt;             multiplex.ConnectInputToOutput(2, 0)&lt;br /&gt;          End Select&lt;br /&gt;       outDevice.Init(multiplex)&lt;br /&gt;       outDevice.Play()&lt;br /&gt;   Catch ex As Exception&lt;br /&gt;       WriteLog(LogType.ErrorMessage, &amp;quot;Error playing file &amp;quot; &amp;amp; filename, ex.Message)&lt;br /&gt;   End Try&lt;br /&gt;Catch ex As Exception&lt;br /&gt;   WriteLog(LogType.ErrorMessage, &amp;quot;Error opening audiodevice or creating audio stream&amp;quot;, ex.Message)&lt;br /&gt;End Try&lt;br /&gt;&lt;br /&gt;Any help would be greatly appreciated!</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="c6c02e59-3584-4c57-aee4-217ce5e3b5b1">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2013-04-25 15:30:27</date>
      <content>hi Peter - it&amp;#39;s a slightly tricky problem, but I&amp;#39;d do it with a couple of custom Wave/Sample providers. One would simply pass on the audio read through your Mp3FileReader and set a flag when it reaches the end (Read returns 0). Then it would notify your custom silence producing WaveProvider allowing it to stop producing zeros.&lt;br /&gt;&lt;br /&gt;Either that or you customise the multiplexer to be able to stop when the first input reaches its end (rather than currently it waits for the last)</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="b2e91207-037f-4e49-b942-5ac5ce88710a">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2013-04-25 15:47:16</date>
      <content>I&amp;#39;d just write a custom Wave/SampleProvider to do this. Left right samples are interleaved, so you&amp;#39;d need to store a bit of history for the channel you wanted to delay, but it would be fairly straightforward bit manipulation</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a23c3820-d1bb-4b58-ab5d-cfb337224241">
      <author>Peter van Ekeren</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/07132348897522279594</website>
      <ip />
      <userAgent />
      <date>2013-05-15 12:18:01</date>
      <content>Hi Mark,&lt;br /&gt;&lt;br /&gt;I&amp;#39;m sorry for responding this late. I didn&amp;#39;t see your response until now.&lt;br /&gt;&lt;br /&gt;Thanks for your solution! I did get it to work but I cheated a bit.&lt;br /&gt;&lt;br /&gt;I created a second stream of the same source file and set the volume to 0. Then I feed two streams to the multiplexer and voila (:&lt;br /&gt;&lt;br /&gt;This works for now, but I&amp;#39;ll look into your solution since it&amp;#39;s cleaner.&lt;br /&gt;&lt;br /&gt;Thanks again!&lt;br /&gt;&lt;br /&gt;-code:&lt;br /&gt;&lt;br /&gt;firstOutputStream = CreateInputStream(localFilePath, 1.0F)&lt;br /&gt;secondOutputStream = CreateInputStream(localFilePath, 0.0F)&lt;br /&gt;outDevice = New WasapiOut(device, AudioClientShareMode.Shared, True, 0)&lt;br /&gt; Try&lt;br /&gt;  Dim multiplex As MultiplexingWaveProvider&lt;br /&gt;  multiplex = New MultiplexingWaveProvider(New IWaveProvider() {firstOutputStream, secondOutputStream}, 2)&lt;br /&gt;  Select Case _channel&lt;br /&gt;   Case 0&lt;br /&gt;    With multiplex&lt;br /&gt;     .ConnectInputToOutput(0, 0)&lt;br /&gt;     .ConnectInputToOutput(2, 1)&lt;br /&gt;    End With&lt;br /&gt;   Case 1&lt;br /&gt;    With multiplex&lt;br /&gt;     .ConnectInputToOutput(0, 1)&lt;br /&gt;     .ConnectInputToOutput(2, 0)&lt;br /&gt;    End With&lt;br /&gt;   End Select&lt;br /&gt;  outDevice.Init(multiplex)&lt;br /&gt;  outDevice.Play()&lt;br /&gt; Catch ex As Exception&lt;br /&gt; &lt;br /&gt; End Try</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="d3c4f067-274a-4f6f-bf7c-2aefad081d83">
      <author>John</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2013-07-28 03:50:02</date>
      <content>I&amp;#39;m trying to make a sine wave play in only one ear. No matter what I do it plays in both ears. I feel like I&amp;#39;ve tried every inputToOutput combination and I still get it output on both sides.&lt;br /&gt;&lt;br /&gt;Here&amp;#39;s my code.. what am I doing wrong?? &lt;br /&gt;&lt;br /&gt;NOTE: Both SineWaveProvider and SilentWaveProvider work on their own.&lt;br /&gt;      _waveOutput is a class level private object of type WaveOut&lt;br /&gt;&lt;br /&gt;public void Play()&lt;br /&gt;{&lt;br /&gt;            var sineWaveProvider = new SineWaveProvider();&lt;br /&gt;            sineWaveProvider.Frequency = Frequency;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;            var swp = new SilentWaveProvider();&lt;br /&gt;&lt;br /&gt;            var mwp = new MultiplexingWaveProvider(new IWaveProvider[] { swp, sineWaveProvider }, 2);&lt;br /&gt;&lt;br /&gt;            &lt;br /&gt;            mwp.ConnectInputToOutput(0, 0);&lt;br /&gt;            mwp.ConnectInputToOutput(1, 1);&lt;br /&gt;            &lt;br /&gt;            _waveOutput = new WaveOut();&lt;br /&gt;            _waveOutput.Init(mwp);&lt;br /&gt;            _waveOutput.Play();&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;////////READ FUNCTION OF SineWaveProvider/////////////////&lt;br /&gt;private int _sample;&lt;br /&gt;&lt;br /&gt;public override int Read(float[] buffer, int offset, int sampleCount)&lt;br /&gt;        {&lt;br /&gt;            int sampleRate = WaveFormat.SampleRate;&lt;br /&gt;&lt;br /&gt;            for(int n = 0; n &amp;lt; sampleCount; n++ )&lt;br /&gt;            {&lt;br /&gt;                buffer[n + offset] = (float)(Amplitude * Math.Sin((2 * Math.PI * _sample * Frequency) / sampleRate));&lt;br /&gt;&lt;br /&gt;                _sample++;&lt;br /&gt;                if (_sample &amp;gt;= sampleRate) _sample = 0;&lt;br /&gt;            }&lt;br /&gt;&lt;br /&gt;            return sampleCount;&lt;br /&gt;        }&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;////////READ FUNCTION OF SilentWaveProvider////////////////&lt;br /&gt;private int _sample;&lt;br /&gt;&lt;br /&gt;public override int Read(float[] buffer, int offset, int sampleCount)&lt;br /&gt;        {&lt;br /&gt;            int sampleRate = WaveFormat.SampleRate;&lt;br /&gt;&lt;br /&gt;            for (int n = 0; n &amp;lt; sampleCount; n++)&lt;br /&gt;            {&lt;br /&gt;                buffer[n + offset] = 0.00f;&lt;br /&gt;&lt;br /&gt;                _sample++;&lt;br /&gt;                if (_sample &amp;gt;= sampleRate) _sample = 0;&lt;br /&gt;            }&lt;br /&gt;&lt;br /&gt;            return sampleCount;&lt;br /&gt;        }&lt;br /&gt;&lt;br /&gt;</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a4473070-2532-4946-8acf-d38b61803a4e">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2013-07-29 16:02:11</date>
      <content>MultiplexingWaveProvider does have unit tests that check this scenario works correctly, so I&amp;#39;m surprised you&amp;#39;re having a problem. How about write some audio to a WAV file and check it in audacity, see what you are actually generating,.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="b0116829-6731-4e5a-9d47-747165dae83e">
      <author>John</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2013-07-31 16:40:45</date>
      <content>Thanks Mark!&lt;br /&gt;I noticed something strange too. In the read function of the SineWaveProvider I tried this:&lt;br /&gt;&lt;br /&gt;buffer[n + offset] = (float)(Amplitude * Math.Sin((2 * Math.PI * _sample * Frequency) / sampleRate));&lt;br /&gt;&lt;br /&gt;buffer[n + offset + 1] = 0.00f;&lt;br /&gt;&lt;br /&gt;When debugging I noticed that the value in buffer[n + offset + 1] wasn&amp;#39;t actually being set to 0.00! (I also tried (float)0; just to be sure it wasn&amp;#39;t something dumb like that). I&amp;#39;m thinking it may be 1 of 2 things: &lt;br /&gt;1) The buffer[] is passed in to the function so it may be possible that something else is accessing the buffer[] at the same time &lt;br /&gt;OR &lt;br /&gt;2) Since i&amp;#39;m using the alpha release of VisualStudio 2013 there MAY be a bug with assigning array values or some other obscure bug. I would think that would be a basic compiler function that would have been mastered many years ago but you never know.&lt;br /&gt;&lt;br /&gt;I&amp;#39;ll try what you suggested when I get home. &lt;br /&gt;I&amp;#39;ll also try it in VisualStudio 2012 and dig into the nAudio source to look for other threads accessing the buffer.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="f8213bfd-5e40-430c-a43c-d79aabc4554c">
      <author>John</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2013-08-04 00:46:25</date>
      <content>This whole time it was MY SOUND CARD!&lt;br /&gt;&lt;br /&gt;I don&amp;#39;t yet know exactly why it&amp;#39;e my sound card but when I tried this on a different machine it worked fine...&lt;br /&gt;&lt;br /&gt;OMFG DUCKSAUCE!&lt;br /&gt;http://xkcd.com/457/</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="ff5181a3-9d67-47cf-9290-4c7641ad20b9">
      <author>vitek</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/01645078423906276937</website>
      <ip />
      <userAgent />
      <date>2013-08-12 18:08:41</date>
      <content>WMA file reader does not see all 6 channels in my input file, just 2! Why? Here is the source:&lt;br /&gt;&lt;br /&gt;var wmaStream = new WMAFileReader(fileName);&lt;br /&gt;wmaStream.WaveFormat.Channels gives 2 instead of 6 (Audacity plays it OK and shows all 6 channels!).&lt;br /&gt;&lt;br /&gt;Any help appreciated.</content>
    </comment>
  </comments>
</post>