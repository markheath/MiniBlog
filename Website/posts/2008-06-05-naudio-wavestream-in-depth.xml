<post>
  <title>The NAudio WaveStream in Depth</title>
  <slug>naudio-wavestream-in-depth</slug>
  <author>Mark Heath</author>
  <pubDate>2008-06-05 07:24:00</pubDate>
  <lastModified>2008-06-05 07:24:41</lastModified>
  <content>&lt;p&gt;Continuing my series of posts documenting the &lt;a href="http://www.codeplex.com/naudio"&gt;NAudio&lt;/a&gt; open source .NET audio library, I will look in a bit more detail today at the &lt;strong&gt;WaveStream&lt;/strong&gt; class, which is the base class for several others in NAudio, and can be overridden to add functionality to the NAudio engine. For a higher level look at where the WaveStream fits into the big picture of Wave mixing, see &lt;a href="/post/naudio-wave-stream-architecture"&gt;this post&lt;/a&gt;.&lt;/p&gt;  &lt;h2&gt;Object Hierarchy&lt;/h2&gt;  &lt;p&gt;&lt;strong&gt;WaveStream &lt;/strong&gt;is an abstract class that inherits from &lt;strong&gt;System.IO.Stream&lt;/strong&gt;. I chose to do this because I wanted it to be easily interoperable with other streaming APIs. However, with hindsight this has not proved to be a crucial feature, and a &lt;strong&gt;WaveStream&lt;/strong&gt; to &lt;strong&gt;Stream&lt;/strong&gt; adapter class could easily be created so a future version of NAudio may change this, which would allow us greater flexibility over the interface design of WaveStream.&lt;/p&gt;  &lt;h2&gt;Abstract Members&lt;/h2&gt;  &lt;p&gt;These members of WaveStream must be implemented by any concrete class that derives from WaveStream. They represent the main functionality of WaveStream. This section serves as a guide to the things you must do if you create a custom WaveStream.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;WaveFormat Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Each WaveStream must report the WaveFormat that it uses (i.e. the sample rate, bit depth, number of channels etc). Some WaveStreams can simply pass on the WaveFormat of their source stream, while others (e.g. the WaveFormatConversionStream) change the format of their source stream, so must provide the output format.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;long Stream.Position Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The Position property is measured in &lt;strong&gt;bytes&lt;/strong&gt;. I had thought for a while about whether it should be measured in &lt;strong&gt;sample frames&lt;/strong&gt;, and this may be an option for a future version of NAudio. The advantage of using bytes is that it is less error prone keeping track of position and ties in with the return value of the Read function. There are some helper methods (see below) that allow you to use TimeSpans to position the stream which is useful for media player applications. Position 0 represents the start of the stream.&lt;/p&gt;  &lt;p&gt;When setting position, you should lock the WaveStream. This is because a Read may well be happening at the same time. Often in audio playback applications, the callback to Read happens in another thread to the main GUI thread.&lt;/p&gt;  &lt;p&gt;Often when you are setting the position, you need to reposition the underlying WaveStream(s). This will often involve a calculation as the input and output WaveFormats may not be the same, or there may be an offset in start positions. If this is the case, be careful to ensure that the underlying stream is never set to a non block-aligned position. If it is, the resulting audio will be garbage.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;long Stream.Length Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This read-only property returns the length of the stream in &lt;strong&gt;bytes&lt;/strong&gt;. This is useful because it allows playback devices to know when the overall playback has ended. The WaveFileWriter also uses this to know how much data to write to the Wave file. Streams that have no definite end position should return &lt;strong&gt;long.MaxValue&lt;/strong&gt;. Sometimes an effect will result in a longer output than the input stream (for example the tail of a reverb effect). In this case, this should be reflected by increasing the Length.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;void Stream.Dispose Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Wave Streams should override the &lt;strong&gt;Dispose(bool disposing) &lt;/strong&gt;method to free any associated resources. The approach taken by NAudio is that WaveStreams will dispose any input WaveStreams when they are disposed, but obviously you can take a different approach if required. By contrast, the WaveStream rendering classes (e.g. WaveOut, WaveFileWriter) do not dispose of their input streams when they are disposed.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;int Read(byte[] destBuffer, int offset, int numBytes) Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This is where the real work of a WaveStream happens. This method will generate the required number of bytes of audio, often by reading from one or more source streams and processing the data in some way. There are a number of key considerations for the implementation of this function.&lt;/p&gt;  &lt;ul&gt;   &lt;li&gt;The code should be highly optimised. This code must run several times a second if playing audio at low latencies. Avoid creating any new objects in this method if possible. &lt;/li&gt;    &lt;li&gt;A lock should be taken to avoid the stream being repositioned during a read, which can cause unpredictable behaviour &lt;/li&gt;    &lt;li&gt;Thought should be given on what to do if insufficient data is available to fulfil the request. With some types of WaveStream it is sufficient to return less than numBytes, but any WaveStream that will be connected directly to an audio output device will need to continue returning data past its own end position. Otherwise there will be nothing to fill the audio device buffers with and playback will stop (or stutter). Obviously if your source is a Wave file you can read ahead, but if your source is an audio capture device, there is no way of reading into the future. &lt;/li&gt;    &lt;li&gt;This function should make sure that the Position property is updated. It is simplest to have a private position member variable that is updated with the number of bytes read each time. &lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Inheriting from System.IO.Stream has meant that we are tied to a Read method signature that is perhaps not ideal in all circumstances. Some WaveStream derived classes would benefit from a Read method that takes an array of floats or shorts, while others would benefit from using an IntPtr or unsafe byte, short or float pointer. This is part of the reason I wish Microsoft would let us &lt;a href="/post/wanted-language-feature-reinterpret"&gt;cast more freely between struct types&lt;/a&gt;. I have some ideas for how the WaveStream base class could be made more flexible in a future version, but for now, you must always write your WaveStream output into the byte array provided.&lt;/p&gt;  &lt;p&gt;Another possible limitation of WaveStream is that it currently offers no way of reporting any latency it introduces. Some types of DSP will introduce a delay. When you are playing back pre-recorded data, it is possible to compensate for that delay. Again, this is something I may look to introduce in a future version of NAudio, particularly if I ever get round to writing a WaveStream that can host a VST effect, which has been a long-term intention of mine.&lt;/p&gt;  &lt;h2&gt;Other WaveStream Members&lt;/h2&gt;  &lt;p&gt;These members of WaveStream are implemented in the base class. You may wish to override some of them, but on the whole they can be left alone.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;bool Stream.CanRead Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Implemented by the WaveStream base class and returns true.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;bool Stream.CanSeek Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Implemented by the WaveSteam base class and returns true.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;bool Stream.CanWrite Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Implemented by the WaveStream base class and returns false.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Stream.Flush Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Implemented by the WaveStream base class. Does not do anything.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Stream.Seek Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This is implemented by the WaveStream base class. It simply turns the methods into a call to the &lt;strong&gt;Position &lt;/strong&gt;property setter.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Stream.SetLength Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Throws a Not Supported Exception.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Stream.Write Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Throws a Not Supported Exception.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;int GetReadSize(int milliseconds)&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Helper function that returns a recommended read size given a desired number of milliseconds of audio. The base class implementation calculates this using the WaveFormat.AverageBytesPerSecond property. This does not typically need to be overridden in derived WaveStream classes.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;int BlockAlign Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The base implementation simply gives quick access to the WaveFormat.BlockAlign property.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;void Skip(int seconds) Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This is a helper method that advances (or rewinds if seconds is negative) by the specified duration.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;TimeSpan CurrentTime Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This helper method allows you to access the current position in terms of a TimeSpan. You can also set the position using this method. The base class implementation uses the WaveFormat.AverageBytesPerSecond property to do its calculation.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;TimeSpan TotalTime Property&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This returns the length of the stream expressed as a timespan.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;bool HasData(int count) Method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;This function is intended to help optimise the mixing of streams. You can ask whether the stream has any non-zero data in the next count bytes. The default implementation returns true if the current Position is less than the Length. Overriding this in derived WaveStream classes allows the mixer to skip over this stream if it has no data, thus speeding things up. However, HasData should always be quick to run.&lt;/p&gt;  </content>
  <ispublished>true</ispublished>
  <categories>
    <category>NAudio</category>
    <category>audio</category>
  </categories>
  <comments>
    <comment isAdmin="false" isApproved="true" id="fc5902cf-7002-48d1-8b0f-297e7424e790">
      <author>jibin</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/09121424418898855997</website>
      <ip />
      <userAgent />
      <date>2010-11-03 06:41:33</date>
      <content>HI,&lt;br /&gt;HOw we can use this waestream class for reading data from networkstream and the play it to the speakers directly using NAudio..&lt;br /&gt;Need to implement a VOIP sample.&lt;br /&gt;Any examples or links helpful to do this&lt;br /&gt;Thanks&lt;br /&gt;jibin&lt;br /&gt;jibin.mn@gmail.com</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="a61df846-ad4e-44a4-8287-6cb7edec263a">
      <author>Mark H</author>
      <email>noreply@blogger.com</email>
      <website>http://www.blogger.com/profile/17900587357903273800</website>
      <ip />
      <userAgent />
      <date>2010-11-08 08:07:03</date>
      <content>you need to create a custom wavestream or WaveProvider that supplies the data you read from the network from the Read method. You&amp;#39;ll need to report the correct WaveFormat, and implement buffering. See the BufferedWaveProvider in the latest code for a good starting point.</content>
    </comment>
    <comment isAdmin="false" isApproved="true" id="991c1c33-95a3-4b8a-b474-faa1efef7f52">
      <author>Anonymous</author>
      <email>noreply@blogger.com</email>
      <website />
      <ip />
      <userAgent />
      <date>2014-01-29 11:10:57</date>
      <content>Hi. I am new in NAudio. i am using wave stream in my program. where i produce two wavestream from two different/similar audio. How can i compare the percentage of similarity between the two wavestream? </content>
    </comment>
  </comments>
</post>